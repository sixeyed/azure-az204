# Kubernetes Services - AZ-204 Exam Exercises

Kubernetes Services are central to the AZ-204 exam's containerized solutions domain, appearing in questions about network configuration, service discovery, and integration with Azure Load Balancer. The exam tests your ability to choose the appropriate Service type for different scenarios, understand DNS-based service discovery, configure Azure-specific networking features, and troubleshoot connectivity issues. These exercises focus on the practical skills and conceptual understanding that distinguish candidates who can actually implement production Kubernetes networking from those who only memorize YAML syntax.

## Service Types and When to Use Each

Understanding when to use each Service type is fundamental to AZ-204 exam success because scenario-based questions hinge on making the right architectural choice. ClusterIP Services provide internal-only access with an IP address that's only reachable within the cluster, making them perfect for backend services, databases, internal APIs, and any component that should never be exposed outside the cluster. When you see exam scenarios describing microservices that need to communicate internally or backend databases that frontend services need to reach, ClusterIP is almost always the answer.

NodePort Services expose applications on a static port across all cluster nodes, typically in the range 30000-32767. Any traffic to any node on that port gets routed to your Service regardless of which node the Pods are actually running on. While NodePort appears in exam questions, it's usually presented as a development or testing solution rather than production. The exam might ask you to troubleshoot connectivity issues where someone used NodePort unnecessarily, or explain why NodePort isn't recommended for production on AKS when better options exist.

LoadBalancer Services are critical for AZ-204 because they represent how you expose applications publicly in Azure Kubernetes Service. When you create a LoadBalancer Service in AKS, Azure automatically provisions an Azure Load Balancer with a public IP address, configures health probes and load balancing rules, and routes traffic to your Pods. This integration is seamless and automatic, which is why LoadBalancer Services are the standard way to expose web applications, APIs, and other public-facing services on AKS. The exam tests whether you understand this integration and can troubleshoot issues like load balancer provisioning failures or unexpected traffic routing.

ExternalName Services provide DNS aliasing for external services, allowing you to give a Kubernetes-style DNS name to services outside your cluster. This is useful when you're migrating from external services to internal ones and want to change where traffic goes without updating application code. While less common on the exam than the other types, ExternalName Services demonstrate advanced understanding of service discovery and DNS manipulation that Microsoft values.

The exam loves scenario-based questions that test Service type selection. If you see requirements like "must be accessible from the internet," think LoadBalancer. For "only internal communication between microservices," think ClusterIP. For "testing on a local cluster without cloud load balancer," think NodePort. For "reference an external database by internal name," think ExternalName. Being able to make this determination quickly based on requirements is essential.

## Label Selectors and Service Discovery

Services find their target Pods using label selectors, and understanding this loose coupling is critical for the exam. When you create a Service, you specify a selector with key-value pairs. The Service continuously watches for Pods matching those labels and automatically updates its endpoints to include all matching Pods. This dynamic discovery means you can scale Pods up and down, they can move between nodes, they can restart with different IP addresses, and the Service keeps tracking them automatically.

The exam tests this concept through scenarios involving scaling and updates. If you scale a Deployment from three replicas to five, Services targeting those Pods automatically start load balancing across all five instances. If a Pod fails health checks and gets restarted, the Service notices the IP change and updates its endpoints. This automatic adaptation is what makes Services so powerful for dynamic environments.

DNS-based service discovery is how applications actually find Services in Kubernetes. When you create a Service named api in the default namespace, Kubernetes DNS automatically creates records so other Pods can reach it using the hostname api or the fully-qualified name api.default.svc.cluster.local. The exam expects you to understand these DNS patterns including the short form within the same namespace, the namespace-qualified form for cross-namespace access, and the fully-qualified form for explicit clarity.

Azure Kubernetes Service uses CoreDNS for cluster DNS, and the exam might test your understanding of how to troubleshoot DNS issues. Common problems include Pods unable to resolve Service names due to CoreDNS failures, incorrect DNS configuration in Pod specs, or network policies blocking DNS traffic. Knowing how to use kubectl exec to test DNS resolution with nslookup or dig is a practical skill the exam values.

## Azure Load Balancer Integration and Configuration

The AZ-204 exam emphasizes Azure Load Balancer integration because it's specific to AKS and represents real-world deployment patterns on Azure. When you create a LoadBalancer Service, AKS automatically provisions an Azure Load Balancer in your cluster's resource group, configures frontend IP configuration with either a public IP or integration with your virtual network, sets up backend pools containing your cluster nodes, creates load balancing rules for each port defined in your Service, and configures health probes based on your Pod readiness checks.

This automation is powerful but the exam tests whether you understand what's happening under the hood. You need to know that the load balancer routes traffic to cluster nodes, not directly to Pods, and that kube-proxy on each node handles forwarding traffic from the node to the actual Pods. This two-tier architecture affects troubleshooting approaches when connectivity issues arise.

Service annotations provide control over load balancer configuration in AKS, and several exam-relevant annotations are commonly tested. The service.beta.kubernetes.io/azure-load-balancer-internal annotation creates an internal load balancer that's only accessible within your virtual network rather than from the internet, essential for private applications. The service.beta.kubernetes.io/azure-load-balancer-resource-group annotation lets you specify which resource group should contain the load balancer, useful for organizational governance. The service.beta.kubernetes.io/azure-dns-label-name annotation assigns a DNS name to your public IP for easier access.

The exam might present scenarios requiring internal load balancers for compliance with security policies, or situations where you need predictable DNS names for load balancers. Knowing these annotations and when to use them demonstrates practical AKS expertise. You should also understand that modifying annotations on an existing Service triggers load balancer reconfiguration, which can cause brief connectivity disruptions during the update.

## Session Affinity and Traffic Distribution

Session affinity is an important concept for the exam because many applications require requests from the same client to reach the same Pod. By default, Services distribute traffic randomly across all healthy Pods, which is perfect for stateless applications but problematic for stateful ones. Session affinity configuration using the sessionAffinity field set to ClientIP causes all requests from the same client IP to route to the same Pod for the session duration.

The exam tests your understanding of when session affinity is necessary and its limitations. You'd use session affinity for applications that maintain in-memory session state, shopping carts that aren't persisted to shared storage, or legacy applications not designed for distributed deployment. However, you need to understand that session affinity based on client IP doesn't work well behind proxies or load balancers that mask original client IPs, and it can cause uneven load distribution if traffic comes from a small number of client IPs.

External traffic policy is another exam-relevant configuration that affects how traffic flows to Pods. The default behavior of Cluster routes traffic to any Pod across the entire cluster, potentially causing an extra network hop if traffic lands on a node without local Pods. Setting externalTrafficPolicy to Local routes traffic only to Pods on the node that received the traffic, preserving source IP addresses and reducing latency but potentially causing uneven distribution if Pods aren't spread evenly across nodes.

The exam might present scenarios involving compliance requirements to preserve client IP addresses for logging or scenarios where latency is critical and you need to minimize network hops. Understanding when to use Local versus Cluster external traffic policy and the trade-offs involved demonstrates the systems thinking that the exam values.

## Headless Services for Advanced Patterns

Headless Services are an advanced concept that appears in exam questions involving stateful applications and direct Pod communication. When you set clusterIP to None in a Service definition, Kubernetes creates a headless Service that doesn't get a cluster IP address. Instead, DNS queries for the Service return the IP addresses of all matching Pods directly. This allows applications to discover and connect directly to individual Pods rather than going through load balancing.

This pattern is essential for stateful applications like databases where you need to connect specifically to the primary instance versus read replicas, for peer-to-peer applications that need to discover all member instances, or for applications using custom load balancing algorithms. StatefulSets often use headless Services because each Pod needs a stable network identity that other Pods can address directly.

The exam tests whether you understand the difference between regular Services that provide load balancing and virtual IP addresses versus headless Services that provide direct Pod discovery. Scenarios involving StatefulSets, database clusters, or applications requiring direct Pod addressing point toward headless Services as the solution.

## Service Mesh Integration and Advanced Networking

While service meshes like Istio and Linkerd may be beyond basic AZ-204 scope, understanding that Services form the foundation for service mesh functionality is important. Service meshes build on top of Kubernetes Services to provide advanced traffic management, security, and observability. The exam might ask about integrating AKS with Azure Service Mesh or understanding how service mesh sidecars interact with Kubernetes Services.

Azure Application Gateway Ingress Controller represents another integration point between Services and Azure networking services. While Ingress is a separate concept, it builds on ClusterIP Services to provide Layer 7 routing and Azure-native load balancing. The exam tests whether you understand how these layers interact and when to use each approach.

Network policies interact with Services by controlling which Pods can communicate with each other at the network level. While a Service makes a set of Pods accessible, network policies can restrict which sources are allowed to reach those Pods. Understanding this layered security model where Services provide discovery and load balancing while network policies provide access control demonstrates comprehensive security knowledge.

## Troubleshooting Service Connectivity

The exam tests practical troubleshooting skills through scenarios involving Service connectivity issues. Common problems include Services not routing traffic because label selectors don't match any Pods, endpoints being empty because no Pods are ready, DNS not resolving Service names due to CoreDNS issues, Azure Load Balancer not provisioning due to quota limits or networking configuration, and network policies blocking traffic to Services.

When troubleshooting Service problems, you need to know the diagnostic flow. Start with kubectl get service to verify the Service exists and has the expected type and ports. Use kubectl describe service to see the selector and endpoints - if endpoints are empty, no Pods match the selector or none are ready. Use kubectl get endpoints to see the detailed endpoint list with Pod IPs. Use kubectl exec to run diagnostic commands inside Pods, testing DNS resolution with nslookup and connectivity with curl or nc.

For Azure Load Balancer issues, check the Azure portal to verify the load balancer was created, inspect backend pools to ensure they contain cluster nodes, review health probes to see if they're passing, and check load balancing rules match your Service port configuration. The exam expects you to navigate both Kubernetes and Azure layers when diagnosing AKS Service issues.

The exam might present scenarios where a Service is created but applications can't reach it, where load balancer provisioning fails with quota errors, or where traffic reaches some Pods but not others. Walking through systematic troubleshooting using kubectl commands and Azure portal verification demonstrates the practical skills Microsoft values in certified developers.

## Cleanup

When you're finished with these exercises, removing Services is straightforward using kubectl delete. However, understanding Service lifecycle is important for production environments and exam questions about cost optimization and resource management. LoadBalancer Services provision Azure Load Balancers that incur costs, so cleaning up test Services prevents unexpected charges. The exam values understanding these operational considerations that affect cloud costs and resource governance.
