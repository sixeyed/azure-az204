# Kubernetes Deployments - AZ-204 Exam Exercises

Deployments are the cornerstone of application management in Kubernetes and feature prominently in the AZ-204 exam's containerized solutions domain. The exam tests your understanding of declarative updates, rolling update strategies, rollback procedures, scaling operations, and integration with Azure Kubernetes Service features. These exercises focus on the operational patterns and troubleshooting skills that distinguish candidates who can manage production deployments from those who only understand basic YAML syntax. Mastering Deployments is essential because they're the foundation for nearly every stateless application running on Kubernetes.

## Declarative Management and Desired State

Understanding desired state management is fundamental to the AZ-204 exam because it represents the philosophical difference between traditional deployment and Kubernetes-native deployment. When you create a Deployment, you're declaring what you want - the desired state - not issuing commands for how to achieve it. You specify that you want three replicas running version 2.0 of your application, and the Deployment controller works continuously to make reality match your declaration. If a Pod crashes, the controller creates a replacement. If you update the image version, the controller orchestrates a rolling update. This reconciliation loop is the heart of Kubernetes.

The exam tests whether you understand this declarative model through scenarios involving failures and recovery. If a node fails taking three Pods with it, you don't need to manually recreate those Pods - the Deployment controller detects the discrepancy between desired state and actual state and creates new Pods automatically on healthy nodes. This self-healing capability is what makes Deployments so powerful for production systems.

Deployments manage Pods through an abstraction called ReplicaSets, and understanding this three-layer hierarchy is important for exam questions about updates and rollbacks. A Deployment creates and manages ReplicaSets, ReplicaSets create and manage Pods. When you update a Deployment's Pod template, it creates a new ReplicaSet with the updated specification, gradually scales up the new ReplicaSet while scaling down the old one, and keeps the old ReplicaSet around for rollback purposes. This architecture enables zero-downtime updates and easy rollback, both of which are heavily tested concepts.

The exam expects you to know that Deployments are for stateless applications where Pods are interchangeable. When you see scenarios involving web applications, API services, or processing workers, Deployments are the right choice. For stateful applications like databases where each Pod has a unique identity and persistent storage, StatefulSets are needed instead. Being able to distinguish these use cases quickly is essential for scenario-based questions.

## Rolling Updates and Update Strategies

Rolling updates are one of the most exam-relevant Deployment features because they enable zero-downtime deployments, a critical requirement for production applications. When you update a Deployment's container image, Kubernetes gradually replaces old Pods with new ones while ensuring that enough replicas are always running to serve traffic. The maxUnavailable parameter controls how many Pods can be down during the update, and maxSurge controls how many extra Pods can be created temporarily. Understanding these parameters and their effects is essential for exam questions about update strategies.

The default rolling update strategy updates Pods in waves, creating new Pods with the updated specification before terminating old ones. This ensures service continuity but requires enough cluster capacity for both old and new Pods to run simultaneously. The exam tests whether you understand the resource implications - if you're running near capacity and attempt an update with maxSurge set to one, you need enough resources for one extra Pod or the update will block waiting for capacity.

Update speed and safety involve trade-offs that the exam explores through scenarios. A fast update with high maxSurge and maxUnavailable gets new code deployed quickly but risks more simultaneous failures if the new version has problems. A slow update with conservative settings takes longer but limits blast radius if issues arise. The exam might present scenarios with requirements like "must update within 5 minutes" or "cannot risk more than one replica being down" and ask you to configure appropriate parameters.

The Recreate strategy is an alternative that terminates all old Pods before creating new ones, causing downtime but avoiding the complexity of running multiple versions simultaneously. This is appropriate for applications that can't handle multiple versions running concurrently, perhaps due to database migrations or shared state. The exam expects you to recognize when Recreate is necessary versus when rolling updates are preferred.

## Rollback Procedures and Revision History

Rollback capability is a critical Deployment feature heavily tested on the AZ-204 exam. Deployments maintain revision history by keeping old ReplicaSets, allowing you to roll back to any previous revision quickly. Understanding how to perform rollbacks, check rollout status, and view revision history demonstrates operational maturity that the exam values.

When you update a Deployment and something goes wrong - the new version crashes, fails health checks, or causes errors - you can roll back to the previous working version using kubectl rollout undo. The Deployment controller scales down the new ReplicaSet and scales back up the old one, reverting to the known-good state. The exam tests your understanding of this process through scenarios involving failed deployments that need quick recovery.

Revision history is controlled by the revisionHistoryLimit parameter which defaults to ten, meaning Kubernetes keeps the last ten ReplicaSets for potential rollback. Setting this too low risks losing rollback options, while setting it too high consumes cluster resources with old ReplicaSets. The exam might ask about managing revision history or troubleshooting rollback failures when old ReplicaSets have been garbage collected.

Progressive rollouts with pauses enable careful validation before proceeding. You can pause a Deployment mid-update, verify the new version works correctly, then resume to complete the rollout. This manual gate is useful for risky changes where you want to verify each step. The exam tests whether you know how to pause, resume, and monitor rollouts to implement safe deployment practices.

## Scaling Operations and Auto-Scaling

Scaling Deployments is straightforward but the exam tests whether you understand the implications and integrate with other Kubernetes features properly. Manual scaling uses kubectl scale to immediately adjust replica count, useful for handling known traffic spikes or capacity planning. The Deployment controller creates or deletes Pods to reach the new replica count while respecting pod disruption budgets and resource constraints.

Horizontal Pod Autoscaler integration represents advanced scaling that's important for AZ-204. The HPA watches metrics like CPU utilization or custom metrics and automatically adjusts Deployment replica count to maintain target metrics. This automatic scaling is perfect for applications with variable load patterns. The exam expects you to understand HPA configuration including target metrics, minimum and maximum replica counts, and scaling behavior.

Resource requests and limits interact with scaling in ways the exam tests. If you scale up a Deployment but your cluster lacks capacity to satisfy the new Pods' resource requests, those Pods will stay Pending. Understanding this relationship between scaling, resource requests, and cluster capacity is essential for troubleshooting scenarios where scaling operations don't produce the expected number of running Pods.

Cluster autoscaler integration takes this further by automatically adjusting cluster node count based on pending Pods. If you scale a Deployment and insufficient capacity exists, cluster autoscaler provisions new nodes. In Azure Kubernetes Service, this integrates with Virtual Machine Scale Sets to add or remove nodes automatically. The exam tests your understanding of this multi-layer autoscaling from HPA adjusting Pods to cluster autoscaler adjusting nodes.

## Health Checks and Readiness Management

Deployments depend on container probes for intelligent rollout behavior, and the exam tests this integration thoroughly. Liveness probes tell Kubernetes when to restart containers, readiness probes control when Pods receive traffic, and startup probes protect slow-starting containers. Deployments use readiness probes during rolling updates to determine when new Pods are ready to serve traffic and when old Pods can be safely terminated.

During a rolling update, Kubernetes waits for new Pods to pass readiness checks before considering them available and proceeding with the update. If new Pods never become ready - perhaps due to a configuration error or failing health checks - the update stalls with some Pods running the old version and some attempting the new version. The exam tests your ability to diagnose and recover from these stuck rollout scenarios.

Progressive delivery becomes possible through careful probe configuration and manual rollout control. You might deploy a new version with paused rollout, monitor detailed metrics and error rates, gradually increase traffic to new Pods using service mesh or Ingress configuration, and only complete the rollout after validation. While full progressive delivery platforms may be beyond core AZ-204 scope, understanding how probes enable these patterns demonstrates advanced knowledge.

MinReadySeconds is an often-overlooked parameter that the exam uses to test deep understanding. This setting requires new Pods to be ready for a specified duration before considering them available for update purposes. Setting minReadySeconds to thirty seconds means a Pod must pass readiness checks continuously for thirty seconds before the rollout proceeds, preventing premature progression if Pods crash shortly after starting. Scenarios involving Pods that initially appear healthy but crash after a delay point toward minReadySeconds configuration.

## Azure Kubernetes Service Integration

The AZ-204 exam emphasizes Azure-specific features that enhance Deployment capabilities. Azure Container Registry integration with AKS enables seamless image pulling using managed identity or service principal authentication. Understanding how to configure Deployments to pull images from private ACR registries and troubleshoot ImagePullBackOff errors related to authentication or network access is essential practical knowledge.

Azure Monitor and Container Insights provide observability for Deployments running on AKS. You can view replica status, resource utilization, deployment events, and application logs through Azure Monitor workspaces. The exam might ask about setting up monitoring for Deployments or using Container Insights to troubleshoot performance issues. Understanding how Kubernetes events surface in Azure Monitor and how to correlate them with application metrics demonstrates operational expertise.

Azure DevOps and GitHub Actions integration enables automated Deployment updates through CI/CD pipelines. Pipelines can build container images, push to ACR, update Deployment manifests with new image tags, and trigger rolling updates in AKS. The exam tests whether you understand this end-to-end flow from code commit to production deployment and can troubleshoot failures at each stage.

Azure Policy integration provides governance over Deployment configurations in AKS. You can create policies requiring resource limits, enforcing allowed container registries, mandating specific labels, or preventing privileged containers. The exam might present scenarios requiring compliance enforcement and expect you to identify Azure Policy as the solution. Understanding how policies complement Kubernetes admission control demonstrates comprehensive platform knowledge.

## Troubleshooting Deployment Issues

The exam heavily tests troubleshooting skills through scenarios involving Deployment problems. Common issues include ImagePullBackOff errors when containers can't pull images from registries, CrashLoopBackOff when containers start but immediately fail, Pending Pods when insufficient cluster resources exist, stuck rollouts when new Pods never pass readiness checks, and resource quota violations preventing Pod creation.

When troubleshooting Deployments, you need to know the diagnostic flow. Start with kubectl get deployment to check desired versus available replicas - discrepancies indicate problems. Use kubectl describe deployment to see events explaining what the controller attempted - image pull failures, creation errors, and scaling events appear here. Check kubectl get replicasets to verify ReplicaSet creation and Pod template correctness. Finally examine Pods themselves using kubectl describe pod and kubectl logs to diagnose container-level issues.

Rollout status checking using kubectl rollout status provides real-time update progress and identifies stuck rollouts. If an update appears stuck, kubectl rollout history shows previous revisions and kubectl rollout undo performs rollback. Understanding these commands and when to use each is essential for scenario-based questions where you need to recover from failed updates.

Azure portal and kubectl provide complementary troubleshooting views that the exam expects you to navigate. The portal shows Deployment status, replica counts, and integration with Azure resources like load balancers. kubectl provides detailed event history and container logs. Effective troubleshooting uses both tools - the portal for high-level overview and Azure resource status, kubectl for detailed Kubernetes-layer diagnostics.

## Cleanup

When you're finished with these exercises, removing Deployments automatically deletes their ReplicaSets and Pods through cascading deletion. Understanding cleanup behavior is important for exam questions about resource management and cost optimization. Deployments make it easy to remove entire application stacks with a single command, demonstrating the operational advantages of Kubernetes abstractions over managing individual Pods.
