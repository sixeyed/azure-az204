# Azure Table Storage - AZ-204 Exam Exercises

Azure Table Storage appears in the AZ-204 exam within the Develop solutions that use Azure Storage domain. While it's considered a legacy service compared to Cosmos DB, you'll still need to understand when and how to use it, as it appears in many existing Azure solutions and exam scenarios.

## Prerequisites

You should complete the basic Table Storage lab before focusing on exam-specific topics. Understanding table creation, entity structure, and OData queries are fundamental skills. These exercises assume you're comfortable with the basics and ready to explore the decision-making and architecture patterns that appear on the exam.

## AZ-204 Exam Skills Covered

The exam tests your understanding of Table Storage fundamentals including when to choose it over other storage options. You need to know how to work with entities, partition keys, and row keys effectively. Authentication and authorization methods are important, including storage account keys, SAS tokens, and Azure AD integration. Querying capabilities through OData and client libraries appear in coding scenarios. Design patterns and best practices are crucial for architecture questions. Integration scenarios test your knowledge of using Table Storage as a logging sink or lightweight database. Understanding the Cosmos DB migration path helps with modernization questions.

## Table Storage Fundamentals

Understanding core concepts is essential for the exam. Entities are the fundamental data units in Table Storage, analogous to rows in a relational database but with more flexibility. Each entity is a collection of properties with no enforced schema. Partition Key is critical for both the exam and real-world implementation - it's part of the entity's unique identifier and determines data distribution across Azure's infrastructure. Understanding partition key design is crucial for performance and scalability questions. Row Key completes the unique identifier when combined with the partition key. Together, they form the primary key for the entity, and this combination must be unique within the table.

Schema flexibility is a key exam point that distinguishes Table Storage from relational databases. Table Storage does not enforce a fixed schema - entities within the same table can have completely different properties. This is a fundamental difference that could appear in scenario-based questions comparing different storage options. You might see exam questions testing your understanding of when this flexibility is advantageous, such as storing heterogeneous log data or evolving data models, versus when it could cause issues, like when you need strong typing or referential integrity.

## Authentication and Authorization

The exam tests your knowledge of authentication methods for Table Storage. Connection Strings include the account name, account key, and endpoints for all storage services. You need to know the format and when to use connection strings versus other authentication methods. The connection string provides full access to the storage account, making it suitable for trusted environments but requiring careful protection.

Shared Access Signatures are crucial for the exam. Understand how to generate SAS tokens with specific permissions - read, write, delete, or combinations. Token expiry and time-based access control let you create temporary access without sharing master keys. Fine-grained access control at the table, partition, or row level provides precise security. Know the difference between account-level SAS tokens providing access to multiple services versus resource-level SAS tokens restricted to specific tables or entities.

Azure AD Authentication is increasingly important in modern Azure solutions and may appear in security-focused questions. It provides identity-based access without embedding credentials, integrates with role-based access control, and supports managed identities for Azure services. The exam might present scenarios requiring you to choose between authentication methods based on security requirements and operational constraints.

## Querying Data

For the exam, understand both querying approaches. The OData REST API is less common in practice but you should know the URL format for OData queries, how to filter by PartitionKey and RowKey for efficient queries, response formats including XML and JSON options, and the Accept header for controlling response format. The exam might present OData query syntax and ask you to identify what it retrieves.

Client Libraries are more commonly used in practice and likely to appear in code-based exam questions. The Azure.Data.Tables SDK for .NET provides modern async operations. Know how to perform CRUD operations programmatically - Create, Read, Update, Delete. Understand async operations and best practices for performance. The exam might show code snippets and ask you to identify issues or improvements.

## Design Patterns and Best Practices

Exam questions often test your ability to design effective table storage solutions. Partition Key Design is critical for performance - good partition keys distribute data evenly across the storage infrastructure, avoiding hot partitions that receive disproportionate traffic. Consider query patterns when designing keys because queries filtering by partition key are most efficient. Understand the impact on parallel operations where Azure can process different partitions concurrently.

Row Key Design should support your query requirements. It can include timestamps for time-series data, enabling efficient chronological queries. Should enable efficient range queries when needed because row keys are sorted within a partition. Combined with partition key to ensure uniqueness, making the composite key the only uniqueness constraint in Table Storage.

## Integration Scenarios

The exam tests real-world integration knowledge. Logging and Diagnostics represents Table Storage as a sink for application logs - integration with logging frameworks like Serilog provides structured log storage. Timestamp-based partition strategies for log data enable efficient time-range queries. Querying and analyzing log data is straightforward with OData filters or client library queries.

Cost Optimization questions test understanding of the pricing model. There's no cost for empty tables, eliminating the cost of provisioning unused capacity. You pay per transaction and storage used, making it cost-effective for variable workloads. Compared to alternatives like Cosmos DB, Table Storage is significantly cheaper but with fewer features and lower performance guarantees.

## Cosmos DB Migration Path

An important exam point is understanding the relationship between Table Storage and Cosmos DB. Cosmos DB Table API provides compatibility with Table Storage applications, enabling migration with minimal code changes. Migration path from Table Storage to Cosmos DB is straightforward using the compatible API. When to choose one over the other depends on requirements - Table Storage for simple, cost-effective scenarios, Cosmos DB for global distribution and advanced features. Performance and feature differences are significant, with Cosmos DB offering guaranteed low latency, global distribution, and comprehensive SLAs.

## Common Exam Scenarios

Be prepared for questions testing application of knowledge. When you need a simple, cost-effective storage solution for semi-structured data that doesn't require complex queries, Table Storage is often the correct choice due to its simplicity and low cost. When your application experiences performance issues with Table Storage and all requests are hitting the same partition, redesign the partition key strategy for better distribution across partitions to avoid hot partitions. When you need to provide time-limited access to a specific table for a third-party application, generate a SAS token with appropriate permissions and expiry time, avoiding exposure of storage account keys. When you're building a new application that needs global distribution and single-digit millisecond latency, use Cosmos DB instead of Table Storage because Table Storage cannot meet these requirements.

## Technical Limits and Constraints

Know these technical limits for the exam as they affect design decisions. Maximum entity size is one megabyte total across all properties. Maximum property size is sixty-four kilobytes for string properties. Maximum number of properties per entity is two hundred fifty-five including system properties. Partition key and row key size can each be up to one kilobyte. These limits affect how you design entities and might appear in troubleshooting questions.

## Comparison with Other Services

A common exam question type involves comparing storage options. Choose Table Storage when you need simple NoSQL storage without complex query requirements, a cost-effective solution for high-volume simple data, integration with existing storage accounts for unified management, and semi-structured data without complex queries or joins. Choose Cosmos DB when you need global distribution with multi-region writes, low latency SLAs with guaranteed performance, complex queries and indexing for sophisticated data access, and multiple API options including SQL, MongoDB, and Gremlin.

Choose Blob Storage when you need unstructured data storage for files and binary content, large files or media content that don't fit in Table Storage's entity size limits, and object storage with hierarchical namespace for organizing content. The exam tests your ability to match storage services to requirements based on data structure, access patterns, performance needs, and cost constraints.

## Best Practices for the Exam

To prepare for Table Storage questions on the AZ-204 exam, practice creating and querying tables using both the Azure CLI and Portal to build familiarity. Understand partition key design patterns deeply because this affects performance and cost. Work with SAS tokens and understand permission models including scopes and expiration. Practice code-based scenarios using the SDK to prepare for coding questions. Review cost optimization strategies for exam scenarios about reducing costs. Understand the migration path to Cosmos DB for modernization questions.

## Summary

Remember for the exam that Table Storage is part of Storage Accounts, not a standalone service, which affects how you create and manage it. Schema flexibility is both an advantage for heterogeneous data and a consideration for type safety and validation. Partition key design directly impacts performance and scalability, making it a critical design decision. SAS tokens are the preferred method for delegated access without sharing account keys. Consider Table Storage for simple scenarios where cost matters, Cosmos DB for complex scenarios requiring advanced features. Understand the relationship and migration path between Table Storage and Cosmos DB for evolution questions. With hands-on practice and understanding of these concepts, you'll be well-prepared for Table Storage questions on the AZ-204 exam.
