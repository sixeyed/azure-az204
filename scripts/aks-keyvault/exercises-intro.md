We've covered how the Container Storage Interface enables Key Vault to serve as a storage provider, keeping secrets secure in Azure rather than in the Kubernetes cluster. Now let's implement this integration.

We'll begin by creating the AKS cluster with specific add-on flags that enable Key Vault integration. You'll use the enable-addons parameter with azure-keyvault-secrets-provider, which installs the Secrets Store CSI Driver components into your cluster. You'll also enable managed identity, which provides the security principal that AKS nodes will use when connecting to other Azure services. When the cluster is created, you can look in the Portal to see if there's anything in the UI that shows Key Vault integration, but the real proof is in checking the pods running in the kube-system namespace. You'll find pods with names starting with aks-secrets-store-csi-driver, and if you ever need to debug any issues connecting AKS with Key Vault, you can check the logs for those pods.

Next comes creating the Key Vault and authorizing AKS to access it. You'll create a standard Key Vault with default options, then retrieve the client ID of the managed identity that AKS is using for the Key Vault addon. This identity was automatically created when you enabled the add-on. You'll then add a Key Vault access policy that grants the managed identity permission to get secrets. This authorization pattern is important to understand: you don't specifically link an AKS cluster to one Key Vault. Instead, in your Kubernetes deployment model, you specify the details of the Key Vault secrets you want to mount, and AKS tries to access those secrets when you deploy your app. As long as the managed identity has access to the Key Vault, the secrets can be read and injected into the container filesystem.

The interesting part is creating and modeling Key Vault secrets using Kubernetes resources. The Key Vault details are modeled in a special type of resource called SecretProviderClass, which isn't a core Kubernetes resource but is added to the cluster when you install the Key Vault add-on. This provides a fine-grained approach to secrets where you explicitly set which Key Vault objects get made available in the volume mount. For each secret, you specify the objectName (the name in Key Vault), objectType (secret or certificate), and objectAlias (the filename to use in the volume mount). You'll create a Key Vault secret by uploading a local JSON file, then edit the SecretProviderClass YAML with your Azure tenant ID, AKS identity ID, and Key Vault name before deploying it to your cluster.

When you deploy an app using Key Vault volumes, you'll see how the CSI volume integration works in practice. The deployment spec uses a CSI volume with the secrets store driver, specifying the Key Vault SecretProviderClass and mounting it into the container at the app/secrets path. When the pod starts, you can verify that the JSON from the Key Vault secret has been loaded into the container filesystem in the expected place by using kubectl exec to cat the file. When you browse to the app, you should see the secret values displayed on the page, proving that the app successfully loaded the configuration from Key Vault.

The lab exercise explores an important question about configuration updates. ConfigMaps and Secrets in Kubernetes can be updated, and pods mounting them have the contents of the volume updated too, though it can take a few minutes because the data is cached. Your challenge is to discover what happens with the CSI secrets store: if you update the contents of the Key Vault secret, does it flow through into the configurable app? How does the behavior compare to native Kubernetes ConfigMaps?

Finally, the cleanup section shows you how to delete the resource group and change your Kubernetes context back to Docker Desktop. Let's implement secure, centralized secret management for AKS!
