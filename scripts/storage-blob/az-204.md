# Azure Blob Storage - AZ-204 Exam Exercises

Azure Blob Storage appears in the AZ-204 exam under the Develop for Azure Storage domain, which accounts for fifteen to twenty percent of your exam score. This content maps directly to skills Microsoft tests, including metadata management, lifecycle policies, blob versioning, static website hosting, and advanced security features. Understanding these concepts at a practical level is what separates passing from failing the storage questions on the exam.

## Prerequisites

You should complete the basic Blob Storage lab before diving into these exam-focused exercises. The fundamental concepts like creating containers, uploading blobs, and using SAS tokens are essential building blocks. These advanced exercises assume you're comfortable with the basics and ready to explore the enterprise features that appear frequently on the exam.

## AZ-204 Exam Skills Covered

The exam expects you to demonstrate specific skills related to blob storage. You need to know how to set and retrieve properties and metadata on blobs and containers. Performing operations on data using the appropriate SDK is crucial because the exam tests your knowledge of the .NET Storage SDK and common patterns. Implementing storage policies and data lifecycle management appears in cost optimization scenarios. Understanding static website hosting is important because it represents a serverless approach to web hosting. Each of these areas appears regularly in exam questions, so practical experience with all of them is essential.

## Working with Blob Metadata and Properties

Understanding the distinction between metadata and properties is critical for the exam because they serve different purposes and have different constraints. Properties are system-defined attributes like Content-Type, Content-Length, ETag, and Last-Modified. You can view and sometimes modify these, but you can't create new properties - they're defined by the Azure platform. Metadata consists of user-defined key-value pairs that you attach to blobs. This is your custom data about the blob, separate from the blob content itself. The exam frequently tests whether you understand this distinction and know when to use each.

When uploading a blob, you can attach metadata immediately, which is a common exam scenario. How do you categorize or tag blobs for your application without modifying the content? The answer is metadata. You provide multiple key-value pairs during upload, allowing you to add fields like department, owner, project, or any custom classification your application needs. This metadata travels with the blob and can be queried without downloading the actual content.

Retrieving metadata without downloading blob content is an important optimization. You use the metadata show command to retrieve just the metadata, which is much faster and cheaper than downloading the entire blob just to check a tag. The response contains your custom key-value pairs without the blob content itself.

Metadata can be updated independently of blob content, which is useful for updating tags, status flags, or other tracking information. When you update metadata, you're not modifying the blob content or creating a new version - you're just changing the associated tags. This makes metadata perfect for workflow state tracking, categorization, or custom indexing.

Working with blob properties requires understanding what can and cannot be modified. System properties like ETag and Last-Modified are read-only - Azure manages these automatically. However, properties like Content-Type, Content-Encoding, and Cache-Control can be modified and affect how clients handle the blob. Content-Type is particularly important because it affects how browsers display or download files. Setting the correct content type ensures files open correctly rather than downloading as binary data.

For the exam, remember that metadata is often used for tagging, categorization, and custom application logic without modifying blob content. Expect questions about when to use metadata versus when to use blob properties, and understand the constraints of each - metadata is limited to eight kilobytes total, properties have specific purposes and some are read-only.

## Blob Lifecycle Management Policies

Lifecycle management is a critical exam topic that appears in cost optimization scenarios. In production, you don't want to manually move files between tiers or delete old data - that's error-prone and doesn't scale. Lifecycle policies automate this based on rules you define, and this is a favorite exam topic because it combines cost management with automation.

Lifecycle policies are defined in JSON format with rules specifying actions and conditions. A typical policy demonstrates the blob lifecycle progression from Hot to Cool to Archive to deletion. After thirty days without modification, blobs move to Cool tier automatically. After ninety days, they move to Archive tier for long-term retention. After three hundred sixty-five days, they're deleted entirely. This only applies to block blobs, demonstrating the filtering capability.

The policy structure includes actions defining what happens at each stage, filters determining which blobs the rule applies to, and conditions specifying when actions trigger. Understanding this structure is important for exam questions asking you to design or troubleshoot lifecycle policies.

Advanced filtering with prefix matching allows different lifecycle rules for different types of data. A common exam scenario involves log files needing faster archival than user documents. You create policies specifically for logs using prefix matching, where the policy only applies to blobs whose names start with a specific prefix like "logs/". This pattern lets you create different policies for different data categories within the same storage account.

Understanding access tier differences is crucial for exam success. Hot tier is optimized for frequently accessed data with the highest storage cost but lowest access cost, has no minimum storage duration, and provides immediate availability. Cool tier is for infrequently accessed data with lower storage cost than Hot, higher access cost than Hot, a minimum thirty-day storage duration where early deletion fees apply, and immediate availability. Archive tier is for rarely accessed data with the lowest storage cost, highest access cost, a minimum one hundred eighty day storage duration, is offline storage requiring rehydration, and rehydration can take hours with significant early deletion fees.

The exam tests which tier to use for different scenarios. Remember Hot for active data, Cool for thirty-plus day storage with occasional access, and Archive for one hundred eighty-plus day long-term retention with rare access. Understanding the minimum storage durations and early deletion fees is important for cost calculation questions.

## Advanced SAS Token Management

The exam tests three types of SAS tokens, each with different scope and security implications. Account-level SAS provides access to multiple services like Blob, File, Queue, and Table, is less granular but more flexible, and is used for administrative operations. Service-level SAS is specific to one service, provides more granular control over permissions, and is common for application access patterns. User delegation SAS is secured with Azure AD credentials, is the most secure option because it doesn't use account keys, and is recommended for production scenarios.

Creating container-level SAS tokens demonstrates permission control at the container level. You specify exactly which operations are allowed - read, write, delete, list, or combinations thereof. The expiry time limits how long the token remains valid, and the HTTPS-only flag ensures tokens only work over secure connections.

Understanding SAS permission codes is essential for the exam. R means read, allowing download of blob content and properties. W means write, allowing upload of new blobs. D means delete, allowing blob deletion. L means list, allowing listing of blobs in a container. A means add, for appending to append blobs. C means create, for creating new blobs. You combine permissions like "rl" for read and list, or "wdl" for write, delete, and list.

Creating write-only SAS tokens addresses a common exam scenario - a user needs to upload files but should not be able to read existing files. You grant write, delete, and list permissions but explicitly exclude read permission. This security pattern appears frequently in upload scenarios where you want to accept data without exposing existing content.

IP-based SAS restrictions add another security layer by limiting SAS tokens to specific IP addresses or ranges. This is important for security-sensitive scenarios where you want to ensure tokens can only be used from trusted networks. The exam might present a scenario requiring this additional security control.

Remember that SAS tokens can be restricted by IP address or IP range, start and expiry time creating a valid time window, protocol where HTTPS-only is recommended for security, and can be associated with stored access policies for revocation capability. Only stored access policy-based SAS tokens can be revoked before expiry - this is a critical distinction the exam tests regularly.

## Blob Leasing for Concurrency Control

Blob leasing is an advanced topic providing pessimistic concurrency control. This prevents multiple clients from modifying or deleting a blob simultaneously, which is important for scenarios requiring exclusive access. The exam might present a scenario where your application needs to ensure only one instance can modify a configuration blob at a time - blob leasing is the answer.

Acquiring a lease gives you exclusive write access to a blob for a specified duration, typically between fifteen and sixty seconds or infinite. The lease ID returned must be included in all write operations while the lease is active. Without the correct lease ID, attempts to modify or delete the blob fail with a lease conflict error.

Testing lease protection demonstrates how leases enforce exclusive access. Attempting to delete a blob without providing the lease ID fails because there's an active lease protecting it. Only operations that include the correct lease ID succeed, proving that the lease holder has exclusive control.

For the exam, remember that lease duration ranges from fifteen to sixty seconds or can be infinite. Use cases include distributed locking and ensuring exclusive access to resources. All write operations require the lease ID when a lease is active. Leases can be renewed to extend the duration, changed to transfer to a different lease ID, released to voluntarily give up the lease, or broken to forcibly terminate the lease.

## Static Website Hosting

Static website hosting is a popular exam topic because it represents cost-effective, scalable web hosting without managing servers. You can host entire static websites directly from Blob Storage without needing App Service or virtual machines.

Enabling static website hosting is straightforward - you update the blob service properties to enable the feature, specify index.html as the default document that loads for directory requests, and specify 404.html as the custom error page for missing content. Azure automatically creates a special dollar-web container with unique access properties.

The dollar-web container is different from normal containers. While blobs inside aren't directly accessible via the standard blob endpoint for security reasons, they're served through the static website endpoint which is optimized for web serving. This separation provides better security and cleaner URLs without query strings or container names in paths.

Content uploaded to the dollar-web container becomes your website. HTML, CSS, JavaScript, images, and other web assets all go into this container. The directory structure you create within dollar-web maps directly to URL paths on your website.

Getting the website URL shows you where your site is accessible. The URL follows a specific pattern with your storage account name and a special web domain - it's different from the standard blob storage domain, indicating that this is web-optimized serving rather than standard blob access.

For the exam, remember that static websites are publicly accessible by default without requiring authentication. Use Azure CDN for custom domains and HTTPS since storage accounts alone don't support custom domains. The dollar-web container is created automatically when you enable the feature. This approach is great for Single Page Applications built with frameworks like React or Angular. It's a cost-effective alternative to App Service for static content because you only pay for storage and bandwidth, not for compute resources.

## Blob Versioning and Soft Delete

The exam tests your knowledge of protecting data against accidental deletion or modification. Azure Blob Storage offers two key features working together to provide comprehensive protection.

Soft delete retains deleted blobs for a recovery period you specify, typically seven to three hundred sixty-five days. During this retention period, deleted blobs can be undeleted, recovering them completely. After the retention period expires, blobs are permanently deleted and cannot be recovered.

Versioning maintains previous versions of blobs automatically whenever they're modified. Every modification creates a new version, and the current version is what users see by default. Previous versions are preserved and can be accessed or promoted to current if needed. This is powerful for scenarios requiring point-in-time recovery or audit trails of changes.

With versioning enabled, uploading a blob multiple times creates multiple versions automatically. Each version has a unique version ID, and you can list all versions to see the complete history. The isCurrentVersion property indicates which version is currently active.

For the exam, remember that versioning is automatic with no manual version management needed. Soft delete protects against accidental deletion by providing a recovery window. Both features can be enabled simultaneously for maximum protection, combining version history with deletion recovery. Point-in-time restore is available for disaster recovery scenarios where you need to recover an entire container to a previous state. Immutable storage with legal hold and time-based retention policies provides compliance features for regulated industries.

## Critical Blob Storage Concepts for the Exam

Understanding blob types is fundamental. Block blobs are the most common type, used for text and binary data like documents, images, and videos. They're optimized for streaming and can be up to four point seven five terabytes. Append blobs are optimized for append operations, perfect for log files where you only add to the end. You cannot modify existing data, only append, and they have a maximum size of one hundred ninety-five gigabytes. Page blobs are for random read and write operations, used for VHD files for virtual machine disks. They're optimized for frequent random access and can be up to eight terabytes.

The exam often asks which blob type to use for a described scenario. Look for keywords - frequent updates or random access suggests page blobs, log files or append-only patterns suggest append blobs, and general file storage suggests block blobs.

Cost optimization through access tiers is heavily tested. Hot tier for frequently accessed data has high storage cost but low access cost with no minimum storage duration. Cool tier for thirty-plus day retention has lower storage cost, higher access cost, and a thirty-day minimum with early deletion fees. Archive tier for one hundred eighty-plus day retention has the lowest storage cost, highest rehydration cost, one hundred eighty-day minimum, and is offline requiring hours for rehydration.

SAS token security models have clear hierarchy. User delegation SAS is most secure using Azure AD credentials without exposing account keys, recommended for production. Service-level SAS provides single-service access with granular control, common for applications. Account-level SAS provides multi-service access with less granular control, used for administrative operations.

## Common Exam Scenarios

When you see a scenario about providing temporary read access to a private blob for external users where access should expire automatically and be revocable, generate a Service-level SAS token backed by a stored access policy. The policy allows revocation even before expiry, and the SAS provides time-limited access without exposing account keys.

For automatic data archival where logs are actively accessed for seven days, occasionally accessed for thirty days, and rarely accessed after that, with deletion after two years while minimizing storage costs, implement a lifecycle management policy. Keep in Hot for seven days, move to Cool at seven days for the occasional access period, move to Archive at thirty days for long-term retention, and delete after seven hundred thirty days which is two years. Use lifecycle policies for automatic tier transitions based on age.

For hosting a static website with custom domain and HTTPS, enable static website hosting on a storage account, upload content to the dollar-web container, configure Azure CDN with a custom domain because storage alone doesn't support custom domains, and enable HTTPS on the CDN endpoint. This combines storage-based hosting with CDN's domain and security features.

For preventing accidental deletion of critical documents while allowing users to update them, enable both soft delete with a retention period like seven to thirty days for recovery capability, and blob versioning to maintain history of changes. Consider immutable storage for regulatory compliance if needed. Soft delete plus versioning provides comprehensive protection against both accidental deletion and unwanted modifications.

For ensuring only one instance can modify a configuration blob when multiple instances might attempt simultaneous modification, use blob leasing to acquire an exclusive lock. Only the instance holding the lease can modify the blob, providing pessimistic concurrency control. This is the standard pattern for distributed locking scenarios.

## Summary

Azure Blob Storage is fundamental to the AZ-204 exam and to building cloud applications. The topics covered - from basic blob operations to advanced lifecycle management and security features - represent the core knowledge Microsoft expects from Azure developers. Practice hands-on with the Azure CLI and Portal, building muscle memory for common operations. Understand the why behind each feature, not just the how, because the exam tests application of knowledge. Focus on scenario-based thinking where you match requirements to appropriate features. Review the Microsoft documentation for each topic to deepen understanding. Take practice exams to identify knowledge gaps before the real exam. With thorough preparation and hands-on practice, you'll be ready to demonstrate your Azure development expertise.
