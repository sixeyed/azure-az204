We've covered Request Units as the currency for Cosmos DB compute cost. Now let's measure RU consumption and optimize performance by exploring different approaches to data modeling and querying.

You'll start by looking at the reference documentation to understand serverless mode, consistency levels, SQL queries, and securing access to data. Then you'll create a CosmosDB container with fixed performance by setting up a database with a specific performance level of 500 RU per second. This uses the standard provisioning model where you pay for a level of RU performance whether you hit that level or not. You'll also create a document container with a custom index policy that only indexes the ID field. This is interesting because CosmosDB normally indexes every field in a document which speeds up queries at the expense of inserts and storage. By using a custom policy you can focus performance where you need it.

Next, you'll move into estimating RU usage by uploading 1000 product documents and running queries to measure consumption. You'll see how different query patterns affect RU costs. A query selecting all fields versus selecting specific fields shows interesting differences in execution time and retrieved document size. More importantly, you'll discover that querying on an indexed field versus a non-indexed field makes a huge difference. The name field without an index requires Cosmos to read every row leading to much higher RU costs. The id field with an index only loads one document with much lower cost. These are small numbers but that's still a big difference, and you can see that RUs are calculated from multiple factors including query execution time and index lookup time.

After that, you'll explore alternative data modeling and RUs by trying a bulk load approach. Instead of storing 1000 individual product documents, you'll store all products as an array inside a single document. Application code can fetch all the products in a single document from Cosmos cheaply and then filter the list in memory. The app can use an expiration cache so the list in memory gets refreshed every few minutes. You'll create a new container for reference data and compare index settings with the previous container to see how the default indexes all fields. Run queries to fetch all products and filter for one product, and you'll see dramatic RU cost differences. If your app fetched every product individually at high scale, you'd nearly hit the throughput limit. If your app used bulk loading and instances cached the results, you'd use less than 10 percent of the throughput. This shows you need to model your data and architect your application carefully when using CosmosDB at high scale.

The lab exercise asks you to find the cheapest way to read individual documents using point reads. Fetching documents using the object ID and partition key costs just 1RU for documents up to 100KB. You'll check the RU cost and look for any expensive parts of the query. Finally, you'll look at cleanup procedures to remove all the resources. Let's optimize Cosmos DB performance and cost!
