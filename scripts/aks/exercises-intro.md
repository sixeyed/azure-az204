We've covered what AKS is and why it's valuable for container orchestration. Now let's get hands-on and create your first Kubernetes cluster in Azure.

Before diving into the command line, we'll start by exploring in the Portal to see all the options available when creating a Kubernetes Service resource. You'll examine the different presets that give you good starting configurations for development, production, or cost-optimized scenarios. The node configuration shows you how to choose the number of nodes and VM size, which determines your cluster's capacity. You'll discover node pools, which let you have different groups of nodes with different configurations all in the same cluster. Maybe you have ten Linux nodes in one pool, five Linux servers with GPUs in another pool, and two Windows servers in a third pool. The Portal also reveals the security options, including Kubernetes Role-Based Access Control linked to Azure accounts, and the ACR integration that lets you pull private images without extra authentication configuration.

From there, we'll create an AKS cluster with the CLI using the az aks create command. You'll specify your resource group, cluster name, node count, and VM size. This process takes several minutes, so while it's running, you can browse back to the Portal and look at your resource groups. You'll notice something interesting: in addition to the labs-aks resource group you created, there's another one with a name that begins with MC underscore. When you look inside that managed resource group, you'll find all the underlying infrastructure: virtual machines, network interfaces, load balancers, and network security groups. This separation is important to understand.

Once the cluster is ready, you'll start using the cluster by downloading credentials with the az aks get-credentials command. This configures kubectl to talk to your AKS cluster by adding a new context. You can see all your kubectl contexts and verify which one is active, then run kubectl get nodes to see your cluster nodes running in Azure, all in the Ready state.

The exciting part comes when you're deploying applications to your AKS cluster. You'll work with three YAML files: a ConfigMap that sets the environment name to PROD, a Deployment that defines how the application runs, and a Service that routes external traffic coming in on port 80 to your application Pods. You can deploy all the YAML files in a folder with a single kubectl apply command. After deployment, you'll check the Pods and Services to see everything running. The Service initially shows its external IP address as pending while Azure provisions the public IP and configures the load balancer, but within a couple of minutes, you'll have a publicly accessible IP address. When you browse to that address, you'll see your application running in the AKS cluster. You can even search through the Portal to find the Azure resources that provide the IP address and route traffic to the cluster VMs.

The lab exercise has you exploring cluster capacity and scaling. Since you have spare capacity in the cluster, you can run more Pods to serve more users. You'll investigate how to change the Deployment spec to run four Pods instead of one by editing the YAML and applying the changes. Once you have multiple Pods running, you'll experiment with repeatedly refreshing the website in your browser to see the load balancing in action. You'll also explore what happens when you change the environment name in the ConfigMap from PROD to something else and redeploy, discovering whether the site updates immediately or whether there's a delay.

Finally, the cleanup section shows you how to delete the resource group, which also removes the managed MC resource group automatically, and how to change your Kubernetes context back to Docker Desktop. Let's create and explore your first Kubernetes cluster in Azure!
