# Event Hubs Partitioned Consumers - AZ-204 Exam Relevance

## Exam Coverage

Event Hubs is a key topic in the AZ-204: Developing Solutions for Microsoft Azure exam. This lab covers multiple exam objectives related to message-based solutions.

### Relevant Exam Objectives

**Develop message-based solutions (10-15% of exam)**

Specifically, you need to understand:
- Implementing solutions that use Azure Event Hubs
- Processing events with Event Hubs
- Understanding partition keys and consumer groups
- Managing event retention and capture

## Key Concepts for the Exam

### 1. Event Hubs Architecture

**Partitions**: The exam will test your understanding of how partitions work:
- Partitions enable parallel processing and scale
- Partition count is set at creation and cannot be changed
- Events with the same partition key go to the same partition
- More partitions cost more but enable greater scale
- You can have multiple consumers per partition

**Consumer Groups**: You should know:
- Every Event Hub has a $Default consumer group
- Multiple consumer groups can read the same events independently
- Each consumer group maintains its own offset/position
- Consumer groups enable multiple applications to process the same stream
- Similar concept to Service Bus topics but implemented differently

**Retention**: Understand the retention capabilities:
- Basic SKU: 1 day retention
- Standard SKU: 1-7 days retention
- Premium and Dedicated: Up to 90 days retention
- Events are deleted after the retention period
- Capture can store events beyond retention for long-term analysis

### 2. Event Processing Patterns

**Partitioned Consumer Pattern**: This is critical for the exam:
- Uses checkpoint-based processing to track progress
- Stores checkpoints in Azure Blob Storage
- Provides at-least-once delivery guarantee
- Enables automatic load balancing across consumers
- Supports automatic failover when consumers fail

**At-Least-Once Delivery**: Know the implications:
- Every event will be processed at least once
- Events might be processed multiple times if consumer crashes
- Processing logic should be idempotent when possible
- Checkpoint interval affects the window of potential duplicates

**Competing Consumer Pattern**: Understand this architectural pattern:
- Multiple consumers read from the same queue/stream
- Work is distributed across consumers for scale
- Consumers compete for messages/events
- Provides high availability through redundancy
- Event Hubs implements this with partition ownership

### 3. Event Hubs SKUs and Features

The exam may test your knowledge of SKU differences:

**Basic SKU**:
- 1 consumer group per Event Hub
- 1 day message retention
- 100 brokered connections
- Good for development/testing

**Standard SKU**:
- 20 consumer groups per Event Hub
- Up to 7 days retention
- 1000 brokered connections
- Includes Capture feature
- Kafka protocol support
- Required for partitioned consumer pattern

**Premium and Dedicated**:
- Higher throughput and performance
- Longer retention (up to 90 days)
- VNet integration
- Customer-managed keys
- Not covered in detail in this lab

### 4. Capture Feature

You should understand Event Hubs Capture for the exam:
- Automatically stores events to Blob Storage or Data Lake
- Uses efficient Avro format
- Configurable time and size windows
- Creates time-based folder structure
- Does not affect event consumers
- Available in Standard SKU and higher
- Good for archival and batch analytics

### 5. Connection and Security

**Connection Strings**: Know the components:
- Endpoint: The Event Hubs namespace URL
- Shared Access Key Name: The policy name
- Shared Access Key: The authentication key
- Entity path: The specific Event Hub name (optional in connection string)

**Authorization**:
- Shared Access Signatures (SAS) for connection strings
- Azure Active Directory authentication (preferred for security)
- Namespace-level and entity-level access policies
- Different permissions: Manage, Send, Listen

**Best Practices**:
- Use entity-level policies with least privilege
- Producers should have only Send permission
- Consumers should have only Listen permission
- Avoid using the RootManageSharedAccessKey in applications
- Rotate keys regularly

### 6. Blob Storage Integration

The exam may test how consumers use blob storage:
- Checkpoints store the current position (offset) in the stream
- Stored as JSON blobs in the checkpoint container
- One checkpoint per consumer per partition
- Checkpoint structure includes: offset, sequence number, partition ID
- Checkpoints enable recovery after consumer failures

### 7. Configuration and Management

**Creating Event Hubs**: Know the CLI commands:
- `az eventhubs namespace create` - Creates namespace
- `az eventhubs eventhub create` - Creates Event Hub
- `az eventhubs eventhub consumer-group create` - Creates consumer group
- `az eventhubs namespace authorization-rule keys list` - Gets connection strings

**Key Parameters**:
- Partition count (cannot be changed later)
- Message retention in days
- Throughput units (namespace level)
- SKU selection
- Location and resource group

### 8. Scaling and Performance

**Throughput Units**: Understand the capacity model:
- 1 TU = 1 MB/s ingress or 2 MB/s egress
- Set at namespace level
- Can be scaled up or down (or enable auto-inflate)
- Basic and Standard use TUs

**Partition Scaling**:
- Each partition can serve one active consumer per consumer group
- 5 partitions = max 5 concurrent consumers per group
- Multiple consumer groups can scale independently
- Partition key determines which partition receives the event

### 9. Error Handling and Reliability

**Common Scenarios**:
- Consumer crashes before checkpoint - events processed twice
- Consumer lags behind - retention might be exceeded
- Partition ownership changes - automatic rebalancing
- Network failures - automatic retry in SDK
- Throttling - back off and retry

**Best Practices**:
- Checkpoint frequently but not after every event (performance)
- Monitor consumer lag
- Plan partition count for expected scale
- Set appropriate retention period
- Use multiple consumer instances for availability

## Sample Exam Questions

The exam might ask questions like:

1. **You need to ensure that multiple instances of a consumer application process different events from an Event Hub. What should you use?**
   - Answer: Multiple consumer instances within the same consumer group using the EventProcessorClient

2. **Your application needs to process the same events from an Event Hub for both real-time analytics and auditing. What should you configure?**
   - Answer: Two consumer groups - one for analytics and one for auditing

3. **You need to ensure that a consumer application can resume processing after a failure. What should the application use?**
   - Answer: Checkpoint the offset periodically to blob storage

4. **You're designing an Event Hub solution and expect to process 10 MB/s of incoming events. What is the minimum number of throughput units needed?**
   - Answer: 10 TUs (1 TU = 1 MB/s ingress)

5. **Your Event Hub consumer is processing events, but after a crash, some events are processed twice. What is the delivery guarantee?**
   - Answer: At-least-once delivery

## Lab Connection to Exam

This lab demonstrates several exam-critical skills:

1. **Infrastructure Setup**: Creating Event Hub namespace, Event Hub, and consumer groups with appropriate SKU
2. **Security**: Working with connection strings and authorization rules
3. **Consumer Implementation**: Using EventProcessorClient with checkpoint storage
4. **Scaling**: Running multiple consumers and observing load balancing
5. **Reliability**: Testing failover and checkpoint recovery
6. **Consumer Groups**: Using multiple groups for different processing needs
7. **Capture**: Configuring automatic event storage to blob storage

## Additional Study Topics

Beyond this lab, also study:

1. **Event Hubs vs Service Bus**: When to use each service
2. **Event Grid integration**: Event Hubs as an Event Grid source
3. **Kafka protocol support**: Using Event Hubs with Kafka clients
4. **Schema Registry**: Managing event schemas (Premium feature)
5. **Geo-disaster recovery**: Pairing namespaces for failover
6. **Monitoring**: Using metrics and diagnostic logs
7. **Azure Active Directory**: Using managed identities instead of connection strings

## Hands-On Practice Recommendations

To prepare for the exam:

1. Practice creating Event Hubs with different configurations
2. Write consumer code using EventProcessorClient
3. Test checkpoint recovery scenarios
4. Configure multiple consumer groups
5. Enable and verify Capture
6. Monitor partition distribution and consumer lag
7. Practice with both CLI and Portal
8. Implement error handling and retry logic

## Documentation to Review

Make sure you're familiar with:
- Event Hubs overview and concepts
- EventProcessorClient API documentation
- Partition keys and routing
- Consumer groups deep dive
- Checkpointing and error handling patterns
- Scaling guidance
- Security best practices

The hands-on experience from this lab combined with understanding the concepts above will prepare you well for Event Hubs questions on the AZ-204 exam.
