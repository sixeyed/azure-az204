Now that you understand the basics of ACI, let's explore something more advanced - running distributed applications with multiple containers working together.

We'll start by deploying a distributed app with ACI YAML, using Azure's native specification format to define multi-container groups. You'll work with a random number application that has two components: an API container and a web frontend container. The YAML model defines both containers in a single container group, which means they share the same network space and can communicate with each other using localhost. You'll notice some specific requirements in the ACI YAML format - container sizes for CPU and memory are mandatory because ACI needs to provision the right amount of compute. The environment variables show how the web container connects to the API using localhost rather than external networking. You'll also see how public services require port specifications at both the IP address level and the container level.

After deploying the first version, you'll make a configuration change to increase the logging level by adding environment variables. When you redeploy with the updated YAML file, you'll observe something important about container lifecycle: ACI doesn't update containers in place. Instead, it kills the old containers and creates new ones with the updated configuration. You can watch this happen in the Portal's events table, where you'll see entries for containers being started and the old ones being killed. This is a fundamental truth about all container runtimes, not just ACI.

Next, we'll deploy a Compose app to ACI using Docker's more familiar syntax. The Docker Compose model is simpler than the ACI YAML because the Compose integration takes care of some ACI-specific details automatically. You'll set up a Docker context pointing to your Azure resource group, then use standard docker compose up commands to deploy the application. When you list your containers with docker ps, you'll see not just the two containers you defined, but a third one that Docker's ACI integration added automatically to help with networking. This demonstrates how the Docker CLI handles some of the ACI complexity for you.

The exercises then move into working with ACI containers and storage accounts, where you'll see two different approaches to persistent data. First, you'll use Blob Storage as a database through connection strings, running a container locally to see how it uploads data to Azure Storage. Then you'll explore Azure Files integration, where you mount a file share directly into the container's filesystem. The application thinks it's writing to local storage, but the files actually persist in Azure Files. You'll edit an ACI YAML file to configure both the Blob Storage connection string and the Azure Files volume mount, including the storage account name and key.

The lab exercise challenges you to think about scaling and load balancing with ACI. You'll deploy another copy of the Asset Manager application and explore whether multiple instances can write to the same file share. This raises interesting questions about ACI's limitations - it doesn't have built-in horizontal scaling or load balancing features, so you'll need to think about how to handle traffic distribution between multiple instances.

Finally, the cleanup section shows you how to delete the resource group and reset your Docker context back to local. Let's see how to build distributed container applications on ACI!
