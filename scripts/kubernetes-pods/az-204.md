# Kubernetes Pods - AZ-204 Exam Exercises

Kubernetes Pods appear prominently in the AZ-204 exam under the containerized solutions domain, and mastering them is essential because every other Kubernetes resource builds on Pod concepts. The exam tests not just your ability to deploy Pods, but your deep understanding of their lifecycle, communication patterns, and integration with Azure services. These exercises focus specifically on the scenarios and features you'll encounter in exam questions, going beyond basic Pod creation to explore multi-container patterns, probes, resource management, and troubleshooting.

## Pod Lifecycle and State Management

Understanding the Pod lifecycle is critical for the AZ-204 exam because many questions involve troubleshooting scenarios where you need to identify what's happening based on Pod state. When you create a Pod, it starts in Pending state while Kubernetes schedules it to a node and pulls container images. If you see a Pod stuck in Pending, the exam expects you to check for issues like insufficient cluster resources or image pull errors that prevent scheduling or startup.

Once the containers start running, the Pod moves to Running state. This means at least one container is executing successfully. Not all containers have to be running for the Pod to show Running status, which is an important distinction. As long as one container is up, you're in Running state.

Eventually Pods reach terminal states. Succeeded means all containers completed successfully and won't be restarted, which you'll see with batch jobs or tasks that run to completion. Failed means at least one container terminated with an error, and understanding why a Pod failed by checking logs and events is a practical skill the exam tests directly.

Intermediate states like CrashLoopBackOff appear frequently in exam scenarios. This happens when a container keeps failing and Kubernetes implements a backoff strategy between restart attempts. The restart delay increases exponentially to prevent overwhelming the system with constant restarts. Recognizing this pattern and knowing how to investigate it separates those who pass from those who don't.

The exam might present a scenario where a Pod is in an unexpected state and ask you to diagnose the issue. You need to understand the transitions between states and what causes each transition. Pending to Running requires successful scheduling and image pulling. Running to Failed requires a container to exit with an error. Understanding these state transitions at a deep level is essential.

## Creating and Configuring Pods

The exam expects you to know how to create Pod specifications from scratch, not just copy and paste YAML. Every Pod spec requires four fields - apiVersion, kind, metadata, and spec. For apiVersion, Pods use v1 because they're part of the core Kubernetes API. This is different from other resources that might use apps/v1 or batch/v1.

In the metadata section, you must provide a name that follows Kubernetes naming conventions. You can also add labels, which are key-value pairs used for organizing and selecting Pods. Labels are critically important because they're how Services find Pods, how you group resources, and how deployment strategies work. The exam will test your understanding of label selectors and how they connect different Kubernetes resources.

The spec section defines the containers. Each container needs a name and an image reference. You should also know how to set resource requests and limits, which define how much CPU and memory your container needs and is allowed to use. Requests are used for scheduling decisions - Kubernetes won't place a Pod on a node that can't satisfy its requests. Limits are enforced at runtime - if your container exceeds its memory limit, it gets killed.

Environment variables can be set directly in the spec or pulled from ConfigMaps and Secrets. The exam will definitely include questions about injecting configuration into Pods. You need to understand both the env approach for individual variables and the envFrom approach for loading entire ConfigMaps or Secrets. Knowing when to use each method and how they differ is exam-critical knowledge.

## Multi-Container Pod Patterns

Multi-container Pods are heavily emphasized in the AZ-204 curriculum, and there are three key patterns you must master. The Sidecar pattern is the most common, where a sidecar container enhances the main application container. Classic examples include log shippers that collect logs and send them to a central location, or monitoring agents that gather metrics. The sidecar runs alongside your application and provides supporting functionality without modifying the application itself.

The Adapter pattern uses a helper container to standardize output from the main container. For instance, if your application outputs logs in a custom format, an adapter container can transform them into a standard format that your logging system expects. This pattern is perfect when you need to integrate legacy applications with modern monitoring or logging infrastructure without changing the application code.

The Ambassador pattern uses a proxy container to represent the main container to the outside world. The ambassador might handle authentication, connection pooling, or routing to different backend services. This abstracts complexity away from the main application and makes it easier to manage external connections.

Here's what the exam expects you to understand about multi-container Pods - all containers in a Pod share the same network namespace and IP address, which means they can communicate using localhost on different ports. They can also share storage volumes, allowing them to exchange data through the filesystem. And critically, they're always scheduled together on the same node and live and die together. If the Pod is deleted, all its containers are deleted. If it's rescheduled to a different node, all containers move together.

## Container Communication Patterns

Understanding container communication is essential for the exam, and there are several scenarios you need to know. Within the same Pod, containers communicate using localhost and different ports. Container A can reach Container B at localhost:port-number because they share the network namespace. This communication is fast and efficient since it never leaves the Pod.

Between Pods, you use the Pod's cluster IP address. Every Pod gets a unique IP that's routable within the cluster, and any other Pod can reach it using this IP. However, Pod IPs are ephemeral - they change when Pods are recreated or rescheduled. That's why you use Services for stable endpoints in production, but you need to understand the underlying Pod IPs for exam scenarios and troubleshooting.

Accessing the Kubernetes API is another important pattern. The kubernetes service is automatically available in every namespace, and applications can discover it via DNS or environment variables. This is how applications interact with the Kubernetes API from inside Pods, which is useful for applications that need to query or manage cluster resources dynamically.

## Container Probes for Health Management

Container probes are critical for AZ-204, and there are three types you must know cold. Liveness probes determine if a container is running properly. If a liveness probe fails, Kubernetes kills the container and restarts it according to the restart policy. Use liveness probes to detect when your application is deadlocked or hung - situations where the process is running but not functioning correctly.

Readiness probes determine if a container is ready to receive traffic. A failed readiness probe doesn't restart the container - it just removes it from Service endpoints so it won't receive requests. Use readiness probes during startup when your application needs time to initialize, warm up caches, or establish database connections. This prevents users from hitting an application that isn't ready to serve traffic yet.

Startup probes protect slow-starting containers from being killed prematurely. They disable liveness and readiness checks until the container finishes starting up. This prevents Kubernetes from killing containers that are legitimately taking a long time to start, which is common with applications that have lengthy initialization procedures.

Each probe can use an HTTP GET request, a TCP socket check, or execute a command inside the container. HTTP probes are common for web applications - you specify a path and port, and Kubernetes makes a GET request. TCP probes are useful for non-HTTP services - Kubernetes attempts to open a socket connection. Command probes execute a command inside the container and check the exit code. Know when to use each type and how to configure them in your YAML, including failure thresholds, initial delays, and periods.

## Resource Management and Quality of Service

Resource management is another key exam topic, and you need to understand the distinction between requests and limits. Resource requests are what you ask for when scheduling - Kubernetes uses these to decide which node to place your Pod on. If a node doesn't have enough available resources to satisfy your requests, your Pod won't be scheduled there. Requests represent the minimum resources your Pod needs to function.

Resource limits are the maximum resources your container can use at runtime. If your container tries to exceed CPU limits, it gets throttled - its CPU usage is restricted to the limit. If it exceeds memory limits, it gets killed with an out-of-memory error. Limits prevent a single Pod from consuming all resources on a node and affecting other workloads.

Here's what you need to remember for the exam - requests are for scheduling decisions, limits are for runtime enforcement. You can set both for CPU and memory. Best practice is to always set requests so Kubernetes can make intelligent scheduling decisions, and set limits to prevent runaway containers from affecting other workloads. The relationship between requests and limits also determines Quality of Service classes, which affect eviction priority when a node runs out of resources.

## Restart Policies and Pod Behavior

Pod restart policies control what happens when containers exit, and there are three options you must know. Always is the default policy - the kubelet always restarts the container when it exits, regardless of the exit code. Use this for long-running applications like web servers, background workers, and other services that should run continuously.

OnFailure means restart only if the container exits with a non-zero status code. Use this for jobs and tasks where successful completion shouldn't trigger a restart. This is perfect for batch processing, data migrations, or any task that runs to completion and should stay stopped when successful.

Never means never restart containers automatically. Use this when you want full control and will handle failures externally through monitoring and alerting systems. This is less common but useful for specialized scenarios where you need complete control over the Pod lifecycle.

For the exam, know which policy to use in different scenarios. Web applications and microservices? Always. Batch jobs and one-time tasks? OnFailure or Never depending on whether you want automatic retry on failure. Understanding these policies and their implications is essential for designing reliable applications.

## Troubleshooting and Diagnostics

Troubleshooting Pods is a practical skill tested on the exam, and you need to know the key kubectl commands. To view logs, use kubectl logs with the Pod name. For multi-container Pods, add the -c flag to specify which container's logs you want. Understanding how to access logs is fundamental for debugging application issues.

To see why a Pod is failing, use kubectl describe pod. This shows events that explain what's happening - image pull failures, scheduling issues, health check failures, and more. The events section at the bottom of the output is particularly valuable because it shows a timeline of what Kubernetes has attempted and where things went wrong.

To check what's happening in real-time, use kubectl get pods with the -w flag for watch mode. This continuously updates the display, showing you state changes and restart counts as they happen. This is perfect for observing Pod behavior during deployments or when troubleshooting intermittent issues.

To execute commands inside a running container for debugging, use kubectl exec. The -it flags give you an interactive terminal session inside the container. This lets you inspect the filesystem, check running processes, test network connectivity, and perform other diagnostic tasks from inside the container environment.

Know these commands cold because the exam may present troubleshooting scenarios where you need to identify the right approach. Scenario-based questions are common, like a Pod stuck in Pending - you'd use kubectl describe to see scheduling errors. A Pod in CrashLoopBackOff - you'd use kubectl logs to see why the container is failing. Understanding which tool to use for which problem is exam-critical knowledge.

## Azure-Specific Integration and Features

Since this is the AZ-204 exam, you need to understand Azure-specific aspects of working with Pods. When working with Azure Kubernetes Service, Pods can integrate seamlessly with other Azure services. They can use managed identities to authenticate to Azure resources without storing credentials in your code or configuration. This is the recommended approach for accessing Azure Storage, Key Vault, databases, and other Azure services from Pods.

Azure CNI networking gives each Pod an IP address from your Azure virtual network subnet, allowing direct connectivity from other Azure resources without going through load balancers or ingress controllers. This is different from the default kubenet networking where Pods get IPs from a separate address space. Understanding when to use Azure CNI versus kubenet is important for network design scenarios.

Azure Monitor can collect logs and metrics from your Pods through Container Insights. The exam expects you to understand how to enable container monitoring and configure log collection. This integration gives you visibility into resource usage, performance metrics, and application logs through Azure Monitor workspaces.

Pods can mount Azure Storage - both Azure Files for shared read-write-many storage and Azure Disks for high-performance block storage. Know when to use each type. Azure Files is perfect for shared configuration or data that multiple Pods need to access. Azure Disks provide better performance but can only be attached to one Pod at a time, making them suitable for databases or stateful applications.

## AZ-204 Exam Preparation Strategy

To succeed on the AZ-204 exam regarding Pods, you need to master several key areas. First, understand the complete Pod lifecycle and state transitions cold. Know what each state means, what causes transitions between states, and how to troubleshoot when Pods are in unexpected states.

Second, be able to write Pod YAML specifications from scratch, including containers, resource requests and limits, probes, volumes, and environment variables. The exam might present incomplete YAML and ask you to identify problems or complete missing sections.

Third, understand multi-container Pod patterns deeply. Know the difference between sidecar, adapter, and ambassador patterns, when to use each, and how containers in a Pod share resources and communicate.

Fourth, know how to configure liveness, readiness, and startup probes correctly. Understand the parameters like initialDelaySeconds, periodSeconds, failureThreshold, and when to use HTTP, TCP, or command probes.

Fifth, master resource management including requests versus limits and how they affect scheduling and Quality of Service. Understand what happens when containers exceed their limits and how resource pressure affects Pod eviction.

Sixth, know troubleshooting commands and techniques. Practice using kubectl describe, kubectl logs, kubectl exec, and kubectl get with various flags. Be able to diagnose common issues like ImagePullBackOff, CrashLoopBackOff, Pending state, and resource constraints.

Seventh, understand Azure-specific features like managed identity integration, Azure CNI networking, Azure Monitor integration, and Azure Storage mounting. These differentiate AKS from generic Kubernetes and appear frequently in exam questions.

Practice writing Pod specs from scratch without copying and pasting. Deliberately break things and fix them - deploy Pods with wrong image names, insufficient resources, or bad probes, then practice identifying and resolving the issues. Time yourself using kubectl commands to build speed and confidence. Most importantly, understand not just how but why - the exam tests conceptual understanding and the ability to apply knowledge to new scenarios, not just memorization of YAML syntax.

## Cleanup

When you're finished with these exercises, removing the Pods cleans up all resources. Use kubectl delete with the Pod names or use label selectors to delete multiple Pods at once. Understanding cleanup is part of good operational practices that the exam values.
