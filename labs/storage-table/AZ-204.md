# Azure Table Storage - AZ-204 Exam Exercises

**AZ-204 Exam Domain:** Develop for Azure Storage (15-20%)

This lab extends the basic Table Storage exercises with specific scenarios and skills required for the AZ-204 exam.

## Prerequisites

Complete the basic [Table Storage lab](README.md) first to understand fundamental table operations.

## AZ-204 Exam Skills Covered

- Table Storage SDK operations (insert, query, update, delete)
- Partition key and row key design for optimal performance
- Batch operations and transactions
- Query filtering with OData expressions
- Table Storage vs Cosmos DB Table API comparison
- Performance optimization and best practices
- Pagination and continuation tokens

## Exercise 1: Table Storage Fundamentals

**AZ-204 Critical Topic:** Understanding the structure and operations of Table Storage.

### Create Storage Account and Table

```bash
# Create resource group
az group create -n labs-table-storage-az204 --tags courselabs=azure -l eastus

# Create storage account
az storage account create \
  -g labs-table-storage-az204 \
  -n <storage-name> \
  --sku Standard_LRS \
  --kind StorageV2

# Get connection string
CONNECTION_STRING=$(az storage account show-connection-string \
  -g labs-table-storage-az204 \
  -n <storage-name> \
  --query connectionString -o tsv)

# Create table
az storage table create \
  --name employees \
  --connection-string "$CONNECTION_STRING"
```

List tables:

```bash
az storage table list \
  --connection-string "$CONNECTION_STRING" \
  -o table
```

> **AZ-204 Exam Tip:** Table Storage basics:
> - **NoSQL key-value store** for semi-structured data
> - **Schema-less**: Each entity can have different properties
> - **Partition Key + Row Key**: Unique identifier for each entity
> - **Properties**: Each entity can have up to 252 properties (plus 3 system properties)
> - **Maximum entity size**: 1 MB
> - **Property types**: String, Binary, Boolean, DateTime, Double, Guid, Int32, Int64

## Exercise 2: Partition Key and Row Key Design

**AZ-204 Critical Topic:** Proper key design is essential for performance and scalability.

### Understanding Keys

```bash
# Insert entity with specific partition and row keys
az storage entity insert \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --entity PartitionKey=Engineering RowKey=E001 Name=Alice Email=alice@contoso.com Department=Engineering Salary=85000

az storage entity insert \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --entity PartitionKey=Engineering RowKey=E002 Name=Bob Email=bob@contoso.com Department=Engineering Salary=90000

az storage entity insert \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --entity PartitionKey=Sales RowKey=S001 Name=Charlie Email=charlie@contoso.com Department=Sales Salary=75000
```

Query by partition:

```bash
# Query all entities in Engineering partition (efficient)
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "PartitionKey eq 'Engineering'" \
  -o table
```

ðŸ“‹ Query for a specific employee using both PartitionKey and RowKey (most efficient).

<details>
  <summary>Not sure how?</summary>

```bash
az storage entity show \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --partition-key Engineering \
  --row-key E001
```

Or using query:

```bash
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "PartitionKey eq 'Engineering' and RowKey eq 'E001'"
```

</details><br/>

> **AZ-204 Exam Tip:** Key design best practices:
> - **Partition Key**: Determines data distribution and query efficiency
>   - Entities with same partition key are stored together
>   - Queries within single partition are faster
>   - Choose value with good distribution to avoid hot partitions
>   - Examples: Department, Region, CustomerId, Date (YYYY-MM)
>
> - **Row Key**: Unique within partition, sorts entities
>   - Combined with partition key forms unique identifier
>   - Entities are sorted by row key within partition
>   - Examples: EmployeeId, OrderId, Timestamp
>
> - **Query performance** (fastest to slowest):
>   1. Point query (PartitionKey + RowKey)
>   2. Partition scan (PartitionKey only)
>   3. Table scan (no keys specified)

### Key Design Patterns

**Pattern 1: Department-Employee**
```
PartitionKey: Engineering
RowKey: E001, E002, E003...
```

**Pattern 2: Date-Time (Time series data)**
```
PartitionKey: 2025-11 (YYYY-MM)
RowKey: 2025-11-05T10:30:00_TransactionId
```

**Pattern 3: Geographic**
```
PartitionKey: US-West
RowKey: CustomerId
```

**Pattern 4: Reverse key for range queries**
```
PartitionKey: CustomerA
RowKey: 9999999999999 - Timestamp (for descending order)
```

## Exercise 3: Insert, Update, and Delete Operations

### Insert Operations

```bash
# Insert entity
az storage entity insert \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --entity PartitionKey=Marketing RowKey=M001 Name=David Email=david@contoso.com Department=Marketing Salary=80000 Active=true HireDate=2024-01-15

# Insert or replace (upsert)
az storage entity insert \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --entity PartitionKey=Marketing RowKey=M001 Name=David Email=david@contoso.com Department=Marketing Salary=82000 Active=true \
  --if-exists replace

# Insert or merge (update only specified properties)
az storage entity merge \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --entity PartitionKey=Marketing RowKey=M001 Salary=85000 Title=Manager
```

### Update Operations

```bash
# Update (replace entire entity)
az storage entity replace \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --entity PartitionKey=Engineering RowKey=E001 Name=Alice Email=alice@contoso.com Department=Engineering Salary=90000 Title=SeniorEngineer

# Merge (update specific properties)
az storage entity merge \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --entity PartitionKey=Engineering RowKey=E001 Salary=95000
```

### Delete Operations

```bash
# Delete entity
az storage entity delete \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --partition-key Marketing \
  --row-key M001
```

> **AZ-204 Exam Tip:** Operation differences:
> - **Insert**: Fails if entity exists
> - **Replace**: Replaces entire entity, fails if doesn't exist
> - **Merge**: Updates specified properties, fails if doesn't exist
> - **Insert or Replace (Upsert)**: Insert if new, replace if exists
> - **Insert or Merge**: Insert if new, merge if exists
> - **Delete**: Removes entity, fails if doesn't exist

## Exercise 4: Batch Operations and Transactions

**AZ-204 Critical Topic:** Batch operations improve performance and support transactions.

### Entity Group Transactions

Create a batch script:

```bash
cat > batch-operations.json << 'EOF'
[
  {
    "PartitionKey": "Engineering",
    "RowKey": "E003",
    "Name": "Eve",
    "Email": "eve@contoso.com",
    "Salary": 87000
  },
  {
    "PartitionKey": "Engineering",
    "RowKey": "E004",
    "Name": "Frank",
    "Email": "frank@contoso.com",
    "Salary": 92000
  }
]
EOF
```

> **AZ-204 Exam Tip:** Batch operation constraints:
> - **Same partition key**: All entities must have same partition key
> - **Maximum 100 operations** per batch
> - **Atomic**: All operations succeed or all fail
> - **Ordered execution**: Operations execute in order specified
> - **Maximum payload size**: 4 MB
> - **Operation types**: Insert, Update, Merge, Delete, Insert or Replace, Insert or Merge
> - **No retrieve operations** in batch

### SDK Batch Example (.NET)

```csharp
using Azure.Data.Tables;
using Azure.Identity;

// Connect to Table Storage
var serviceClient = new TableServiceClient(
    new Uri("https://<storage-name>.table.core.windows.net"),
    new DefaultAzureCredential());

var tableClient = serviceClient.GetTableClient("employees");

// Create batch
var batch = new List<TableTransactionAction>();

// Add operations to batch (all must have same partition key)
batch.Add(new TableTransactionAction(
    TableTransactionActionType.Add,
    new TableEntity("Engineering", "E005")
    {
        { "Name", "Grace" },
        { "Salary", 88000 }
    }
));

batch.Add(new TableTransactionAction(
    TableTransactionActionType.Add,
    new TableEntity("Engineering", "E006")
    {
        { "Name", "Henry" },
        { "Salary", 91000 }
    }
));

// Submit batch transaction
var response = await tableClient.SubmitTransactionAsync(batch);
```

## Exercise 5: Query Filtering with OData

**AZ-204 Critical Topic:** Efficient querying using OData expressions.

### Basic Filters

```bash
# Equals
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "Department eq 'Engineering'"

# Greater than
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "Salary gt 85000"

# Less than or equal
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "Salary le 90000"

# Not equals
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "Department ne 'Sales'"
```

### Complex Filters

```bash
# AND operator
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "PartitionKey eq 'Engineering' and Salary gt 85000"

# OR operator
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "Department eq 'Engineering' or Department eq 'Sales'"

# Combined
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "(Department eq 'Engineering' or Department eq 'Sales') and Salary gt 80000"
```

ðŸ“‹ Query for employees with salary between 80000 and 90000.

<details>
  <summary>Not sure how?</summary>

```bash
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "Salary ge 80000 and Salary le 90000"
```

</details><br/>

> **AZ-204 Exam Tip:** OData comparison operators:
> - **eq**: Equals
> - **ne**: Not equals
> - **gt**: Greater than
> - **ge**: Greater than or equal
> - **lt**: Less than
> - **le**: Less than or equal
>
> Logical operators:
> - **and**: Logical AND
> - **or**: Logical OR
> - **not**: Logical NOT

### SDK Query Example (.NET)

```csharp
using Azure.Data.Tables;

var tableClient = new TableClient(connectionString, "employees");

// Simple filter
var query = tableClient.QueryAsync<TableEntity>(
    filter: "PartitionKey eq 'Engineering'");

await foreach (var entity in query)
{
    Console.WriteLine($"{entity.GetString("Name")}: {entity.GetInt32("Salary")}");
}

// Complex filter with LINQ
var highEarners = tableClient.QueryAsync<TableEntity>(
    filter: entity =>
        entity.PartitionKey == "Engineering" &&
        entity.GetInt32("Salary") > 85000);

// Select specific properties
var names = tableClient.QueryAsync<TableEntity>(
    filter: "PartitionKey eq 'Engineering'",
    select: new[] { "Name", "Email" });
```

### Projection (Select)

```bash
# Select specific properties (reduces payload size)
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "PartitionKey eq 'Engineering'" \
  --select Name,Email
```

## Exercise 6: Pagination and Continuation Tokens

**AZ-204 Topic:** Handling large result sets.

### Understanding Pagination

```bash
# Query with top (limit results)
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --top 2
```

> **AZ-204 Exam Tip:** Pagination details:
> - **Default page size**: 1000 entities
> - **Maximum per page**: 1000 entities
> - **Continuation token**: Used to retrieve next page
> - **Timeout**: 5 seconds for query execution
> - **Empty results**: Continuation token may be present even with no results

### SDK Pagination Example (.NET)

```csharp
using Azure.Data.Tables;

var tableClient = new TableClient(connectionString, "employees");

// Query with pagination
var pages = tableClient.QueryAsync<TableEntity>(
    filter: "PartitionKey eq 'Engineering'",
    maxPerPage: 10);

int pageCount = 0;
await foreach (var page in pages.AsPages())
{
    pageCount++;
    Console.WriteLine($"Page {pageCount}:");

    foreach (var entity in page.Values)
    {
        Console.WriteLine($"  {entity.GetString("Name")}");
    }

    // Continuation token for next page
    if (page.ContinuationToken != null)
    {
        Console.WriteLine("More results available...");
    }
}
```

## Exercise 7: Table Storage vs Cosmos DB Table API

**AZ-204 Critical Topic:** Knowing when to use each service.

### Comparison Table

| Feature | Table Storage | Cosmos DB Table API |
|---------|--------------|---------------------|
| **Latency** | Tens of milliseconds | Single-digit milliseconds |
| **Throughput** | Up to 20,000 ops/sec per partition | Unlimited |
| **Global distribution** | No | Yes (multi-region) |
| **Consistency models** | Strong only | 5 consistency levels |
| **Indexing** | PartitionKey and RowKey only | Automatic indexing of all properties |
| **Query capabilities** | Basic OData | Rich queries |
| **Pricing** | Pay per GB stored | Pay for provisioned throughput (RU/s) |
| **SLA** | 99.9% | 99.99% (single region), 99.999% (multi-region) |
| **SDK compatibility** | Compatible | Same SDK works with both |
| **TTL** | No | Yes |

### Migration from Table Storage to Cosmos DB

```bash
# Create Cosmos DB account with Table API
az cosmosdb create \
  -g labs-table-storage-az204 \
  -n <cosmosdb-name> \
  --capabilities EnableTable \
  --default-consistency-level Session

# Create table in Cosmos DB
az cosmosdb table create \
  -g labs-table-storage-az204 \
  -a <cosmosdb-name> \
  -n employees \
  --throughput 400
```

> **AZ-204 Exam Tip:** Use Table Storage when:
> - Cost is primary concern
> - Data is regional
> - Basic queries are sufficient
> - Single-digit millisecond latency not required
>
> Use Cosmos DB Table API when:
> - Need global distribution
> - Require low latency (< 10ms)
> - Need high throughput
> - Complex queries required
> - Multiple consistency models needed

### SDK Code Works with Both

```csharp
// Works with both Table Storage and Cosmos DB Table API
var tableClient = new TableClient(
    connectionString,  // Can be either Table Storage or Cosmos DB
    "employees");

// Same operations work with both
await tableClient.AddEntityAsync(entity);
var result = await tableClient.GetEntityAsync<TableEntity>("Partition1", "Row1");
```

## Exercise 8: Performance Optimization

**AZ-204 Best Practices:** Optimizing Table Storage performance.

### Query Optimization

```bash
# Inefficient: Table scan (slow)
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "Salary gt 85000"

# Better: Partition scan
az storage entity query \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --filter "PartitionKey eq 'Engineering' and Salary gt 85000"

# Best: Point query (fastest)
az storage entity show \
  --connection-string "$CONNECTION_STRING" \
  --table-name employees \
  --partition-key Engineering \
  --row-key E001
```

### Best Practices Checklist

1. **Key Design:**
   - Choose partition keys that distribute data evenly
   - Avoid hot partitions
   - Design row keys for range queries when needed

2. **Query Optimization:**
   - Always include PartitionKey in queries
   - Use point queries (PartitionKey + RowKey) when possible
   - Use projection to select only needed properties

3. **Batch Operations:**
   - Group operations on same partition into batches
   - Maximum 100 operations per batch
   - Use for improved throughput

4. **Entity Design:**
   - Keep entities small (< 1 MB)
   - Denormalize data when appropriate
   - Use multiple entities for 1-to-many relationships

5. **Network:**
   - Use async operations
   - Implement retry logic with exponential backoff
   - Cache frequently accessed data

### SDK Performance Example

```csharp
using Azure.Data.Tables;
using System.Threading.Tasks;

public class TableStorageService
{
    private readonly TableClient _tableClient;

    public TableStorageService(string connectionString, string tableName)
    {
        _tableClient = new TableClient(connectionString, tableName);
    }

    // Efficient point query
    public async Task<TableEntity> GetEntityAsync(string partitionKey, string rowKey)
    {
        return await _tableClient.GetEntityAsync<TableEntity>(partitionKey, rowKey);
    }

    // Efficient batch insert
    public async Task BatchInsertAsync(List<TableEntity> entities)
    {
        // Group by partition key
        var batches = entities
            .GroupBy(e => e.PartitionKey)
            .Select(g => g.Take(100).ToList()); // Max 100 per batch

        foreach (var batch in batches)
        {
            var transactionActions = batch
                .Select(e => new TableTransactionAction(TableTransactionActionType.Add, e))
                .ToList();

            await _tableClient.SubmitTransactionAsync(transactionActions);
        }
    }

    // Efficient query with projection
    public async IAsyncEnumerable<TableEntity> QueryWithProjectionAsync(
        string partitionKey,
        string[] selectProperties)
    {
        var query = _tableClient.QueryAsync<TableEntity>(
            filter: $"PartitionKey eq '{partitionKey}'",
            select: selectProperties);

        await foreach (var entity in query)
        {
            yield return entity;
        }
    }
}
```

## AZ-204 Exam Study Points

### Key Concepts to Master

1. **Table Structure:**
   - Partition Key + Row Key = Unique identifier
   - Schema-less design
   - Maximum 252 custom properties per entity
   - Property types: String, Binary, Boolean, DateTime, Double, Guid, Int32, Int64

2. **Operations:**
   - **Insert**: Add new entity
   - **Replace**: Replace entire entity
   - **Merge**: Update specific properties
   - **Upsert**: Insert or Replace/Merge
   - **Delete**: Remove entity
   - **Batch**: Up to 100 operations, same partition

3. **Query Performance:**
   - Point query (fastest): PartitionKey + RowKey
   - Partition scan: PartitionKey only
   - Table scan (slowest): No keys

4. **OData Filters:**
   - Comparison: eq, ne, gt, ge, lt, le
   - Logical: and, or, not
   - Always include PartitionKey for better performance

5. **Pagination:**
   - Default/maximum: 1000 entities per page
   - Use continuation tokens for next page
   - Handle pagination in SDK with AsPages()

6. **SDK:**
   - TableServiceClient: Account-level operations
   - TableClient: Table-level operations
   - TableEntity: Entity data
   - Same SDK for Table Storage and Cosmos DB Table API

### Common Exam Scenarios

1. **Scenario:** Store employee data by department with efficient queries
   - **Solution:** PartitionKey=Department, RowKey=EmployeeId

2. **Scenario:** Store time-series IoT data with recent data accessed most
   - **Solution:** PartitionKey=DeviceId, RowKey=ReversedTimestamp (for descending order)

3. **Scenario:** Need to insert 500 entities with same partition key
   - **Solution:** Use batch operations, split into batches of 100

4. **Scenario:** Query high-salary employees across all departments
   - **Solution:** Table scan, consider using partition key in query, or denormalize into separate table by salary range

5. **Scenario:** Application needs sub-10ms latency and global distribution
   - **Solution:** Migrate to Cosmos DB Table API

6. **Scenario:** Store product catalog with categories and subcategories
   - **Solution:** PartitionKey=CategoryId, RowKey=ProductId, denormalize category name into entity

7. **Scenario:** Prevent hot partitions in high-traffic scenario
   - **Solution:** Use hash suffix or distributed partition key strategy

## Best Practices

1. **Design partition keys** for even distribution
2. **Use point queries** whenever possible (PartitionKey + RowKey)
3. **Batch operations** for same partition improve performance
4. **Project only needed properties** to reduce payload size
5. **Implement retry logic** with exponential backoff
6. **Cache frequently accessed** entities
7. **Denormalize data** to avoid complex queries
8. **Monitor hot partitions** and redesign if needed
9. **Use async operations** for better scalability
10. **Consider Cosmos DB** for advanced requirements

## Cleanup

```bash
az group delete -y -n labs-table-storage-az204 --no-wait
```

## Additional Resources

- [Azure Table Storage documentation](https://docs.microsoft.com/en-us/azure/storage/tables/)
- [Table Storage SDK for .NET](https://docs.microsoft.com/en-us/dotnet/api/overview/azure/data.tables-readme)
- [Designing scalable partitioning strategy](https://docs.microsoft.com/en-us/azure/storage/tables/table-storage-design)
- [AZ-204 Study Guide](https://learn.microsoft.com/en-us/credentials/certifications/resources/study-guides/az-204)
